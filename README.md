# Система аналитики с Kafka и PostgreSQL

Сервис для сбора аналитических данных с веб-приложения, обработки через Apache Kafka и сохранения в базу данных PostgreSQL.

## Архитектура системы

Система состоит из следующих компонентов:
- **Веб-приложение (Flask)** - собирает данные о пользователе и отправляет их в Kafka
- **Apache Kafka** - брокер сообщений для обеспечения надежной доставки данных
- **Обработчик данных** - получает данные из Kafka и сохраняет их в PostgreSQL
- **PostgreSQL** - реляционная база данных для хранения аналитической информации

## Собираемые данные

- IP-адрес пользователя
- Временная метка события
- Тип события (просмотр страницы, клик, отправка формы и др.)
- User-Agent браузера
- URL страницы
- Referrer (источник перехода)
- Session ID
- Дополнительные данные в JSON формате

## Структура проекта

- `app.py` - основное веб-приложение Flask
- `kafka_integration.py` - модуль для взаимодействия с Kafka
- `kafka_to_postgres.py` - сервис для получения данных из Kafka и сохранения в PostgreSQL
- `db_models.py` - модели базы данных и функции для работы с PostgreSQL
- `kafka_listener.py` - утилита для прослушивания сообщений в Kafka
- `test_button_click.py` - скрипт для тестирования отправки событий
- `test_db.py` - скрипт для тестирования подключения к базе данных
- `kafka_test.py` - утилита для тестирования работы Kafka
- `docker-compose.yml` - конфигурация Docker для запуска всех компонентов системы
- `Dockerfile` - инструкции для сборки Docker-образа приложения
- `static/` - статические файлы для веб-приложения
- `templates/` - HTML шаблоны для веб-интерфейса

## Установка и запуск

### Способ 1: Через Docker Compose (рекомендуется)

1. Установите Docker и Docker Compose
2. Клонируйте репозиторий
3. Запустите все контейнеры:
```
docker-compose up -d
```

Приложение будет доступно по адресу http://localhost:5000/

### Способ 2: Локальная установка

1. Установите PostgreSQL и Apache Kafka
2. Клонируйте репозиторий
3. Создайте виртуальное окружение Python:
```
python -m venv venv
```
4. Активируйте виртуальное окружение:
   - Windows: `venv\Scripts\activate`
   - Linux/Mac: `source venv/bin/activate`
5. Установите зависимости:
```
pip install -r requirements.txt
```
6. Настройте подключение к Kafka и PostgreSQL в соответствующих файлах
7. Запустите приложение:
```
python app.py
```

## Тестирование

Для тестирования отправки данных можно использовать:

1. Веб-интерфейс по адресу http://localhost:5000/
2. Скрипт для эмуляции нажатия кнопки:
```
python test_button_click.py
```
3. Прослушивание Kafka топика для проверки получения сообщений:
```
python kafka_listener.py
```
4. Просмотр данных в PostgreSQL:
```
python test_db.py
```

## Планы по развитию проекта

1. Подключение второй базы данных (MongoDB) для хранения неструктурированной информации
2. Расширение типов событий и аналитических данных
3. Масштабирование Kafka (добавление дополнительных брокеров и партиций)
4. Интеграция с системами визуализации данных (Grafana и/или Metabase)

## История изменений

21.03.2025
- Настроена интеграция с Apache Kafka
- Настроено сохранение данных в PostgreSQL
- Добавлен и исправлен файл kafka_listener
- Исправлено отправление события, теперь одно нажатие кнопки генерирует одно сообщение
- Автоматически переписан README
